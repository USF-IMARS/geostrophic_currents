---
title: "AVISO+ Velocity Dataset"
author: "Sebastian Di Geronimo"
date: 2025-07-14
format: html
editor: source
---

# ---- Summary of Document ----

Download AVISO+ data to get geostrophic velocities in the Florida Keys. The 
geostrophic velocities can be used to estimate where the Florida Current (FC) is
in relation to the coastline. The years used are 2015 - Nov 2024 (based on 
data availability).

A threshold of >= 0.5 m/s is used to determine the FC based on a Zhang et al., 2022.

12 transects are added to determine the location of the FC based on the typical
MBON/SFER cruise transects. These transects are as close as possible to the 
various transects and are named after the `Line Names` inherent to them. Will
need a `fknms_` metadata spreadsheet to get transect locations.
- can be found in Box > mbon_imars_cruises > blank_sheets > pre_cruise_blank_sheets
  - file: fknms_sample_logsheet_MM_YYYY_blank.xlsx

To save videos per year:
- need to have downloaded `ffmpeg` to animate vectors
  - <https://www.gyan.dev/ffmpeg/builds/>
  - then find the path to the *bin/ffmpeg.exe* in order to run the animation


# ---- AVISO+ Sea Surface Height and Velocity ----

Data downloaded from `Copernicus` for both absolute dynamic topography (m) and
north/east surface velocities (m/s)

Data:       Global Ocean Gridded L4 Sea Surface Heights And Derived Variables
Search:     <https://data.marine.copernicus.eu/products>
Product ID: `SEALEVEL_GLO_PHY_L4_MY_008_047`
Dataset ID: `cmems_obs-sl_glo_phy-ssh_my_allsat-l4-duacs-0.125deg_P1D`
Description: <https://data.marine.copernicus.eu/product/SEALEVEL_GLO_PHY_L4_MY_008_047/description>
Bounds:     
  Lon: -83.8125, -78.3125  
  Lat:  22.8125,  26.4375
Note: Select all data products when downloading from `MyOceanPro`
      If downloading from `description` page, go to `Data access` then `subset`, 
      then `automate`. Copy the `automate` and modify script below to download
      multiple dates.

Data Info:
<https://documentation.marine.copernicus.eu/PUM/CMEMS-SL-PUM-008-032-068.pdf>


Velocites extraction inspired from:
<https://help.marine.copernicus.eu/en/articles/9711615-how-to-plot-current-vectors-using-r>


## Download Data from `Copernicusmarine` App

- using `copernicusmarine.exe` File

From: <https://help.marine.copernicus.eu/en/articles/10750437-copernicus-marine-toolbox-executable-no-installation>

I recommend moving the file to this directory where this project is stored

To start, open `cmd` or `PowerShell` from explorer. `cd` to location where `.exe`
is located. Then run `copernicusmarine login` and enter "Username" and
"Password". Once completed, you should be able to run the download


variables:

adt            - absolute dynamic topography [m]
tpa_correction - instrument drift correction [m]
flag_ice       - ice flag
sla            - sea level anomaly [m]
err_sla        - sea level anomaly error [m]

u - eastward
  ugos           - vector velocity [m/s]
  ugosa          - vector velocity anomly [m/s]
  err_ugosa      - vector velocity error [m/s]
  
v - northward
  vgos           - vector velocity [m/s]
  vgosa          - vector velocity anomly [m/s]
  err_vgosa      - vector velocity error [m/s]




# ---- Setup ----


## Load Libraries

```{r setup, include=FALSE}
if (!nzchar(system.file(package = "librarian"))) 
  install.packages("librarian")

librarian::shelf(
  quiet = TRUE,
  librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
  forcats, lubridate, glue, fs, magrittr, here,
  
  # additional
  gganimate, transformr
)

conflicts_prefer(
  dplyr::filter(), 
  dplyr::select(),
  magrittr::extract()
  )

shelf(ggspatial, sf, ncdf4, stars, terra, geodist, mapview, mapedit, 
      rnaturalearth
      )

# set paths to save shapefiles, and animations
shp_save <- here("data", "raw", "shapefiles")
dir_create(shp_save)

animate_save <- here("data", "plots", "animate")
dir_create(animate_save)

source(here("R", "aviso_functions.R"))
```

### Set `ffmpeg.exe` Location 

To save animations using `ffmpeg`, will need to download a compiled version
- need to have downloaded `ffmpeg` to animate vectors
  - from: <https://www.gyan.dev/ffmpeg/builds/>
  - then find the path to the *bin/ffmpeg.exe* in order to run the animations

```{r ffmpeg-location}
if (!exists("ffmpeg_path") & interactive()) {
  message("Select `ffmpeg.exe` file.")
  ffmpeg_path <- rstudioapi::selectFile(
    caption = "Select `ffmpeg.exe` file",
    label   = "Select ffmpeg.exe")
} 

ffmpeg_path <- eval(ffmpeg_path) %T>% 
  print()

# optionally save path in .Rprofile
if (FALSE) {
  shelf(usethis)
  usethis::edit_r_profile(scope = "project")
}
```



# ---- Load AVISO+ Data ----

## Load Muliple Dates

If there are multiple time dimensions, will load each date into its own list

### Paths to AVISO+ Data

```{r path-multi}
if (!exists("aviso_path") & interactive()) {
  aviso_path <-
    here::here("data") %>%
    rstudioapi::selectFile(path = .)
}

aviso_path <- eval(aviso_path)

aviso_path_full <-
  aviso_path %>%
  dir_ls(regexp = "mems_obs-sl_glo")

# set year(s) to load data
# if multiple separate with `|`
year_to_load <- "2016-01-01"

aviso_path <-
  aviso_path_full %>%
  Filter(\(.x) str_detect(.x, year_to_load), .) %>%
  .[] %T>% 
  {
    .[] %>%
    str_extract("(\\d{4}-.*)\\.nc", group = 1) %>%
    print()
  }
```

### Load AVISO+ Data

Each day is loaded individually and the geostrophic currents (ugos and vgos) and 
absolute dynamic topography (adt) are loaded for each day and are combined.

Velocity (m/s) is calculated by: $ mag = \sqrt{ugos^2 + vgos^2} $

```{r load-multi}
# number of days to skip to reduce data size
skip_dates <- 10

# load aviso data
aviso_days <- aviso_load(aviso_path, .by = skip_dates)

# extract tibble and gridded data
aviso_grid_tibble <- aviso_days$tibble
dat_grid          <- aviso_days$gridded
  
# print the dates loaded
aviso_grid_tibble %>%
  distinct(date)

rm(aviso_days)
```

## Convert to Multi-day Raster

First, grids are converted to lists of rasters then combined to form a raster
cube.

The bounding box is extracted and used to load the coastline.

```{r create-raster}
multi_rast <- 
  unname(dat_grid) %>%
  lapply(.,\(.x) rast(.x, crs = "EPSG:4326")) %>%
  rast()
multi_rast

extents <- ext(multi_rast)
ylim    <- extents[3:4]
xlim    <- extents[1:2]

# load coastline
coast <-
  rnaturalearth::ne_coastline(10, returnclass = "sf") %>%
  st_crop(
    xmin = xlim[1][[1]],
    ymin = ylim[1][[1]],
    xmax = xlim[2][[1]],
    ymax = ylim[2][[1]],
  )
coast

rm(extents)
```


# ---- Create Transects ----

This is created manually upon first instance if `transect2.shp` doesn't exist.

The points from the SFER/MBON cruise are load and the Florida Keys locations
are extracted. Then manual creation of transects are done. 


```{r create-load-transects}
transect_file <- here(shp_save, "transects2.shp")

# stations_path <- rstudioapi::selectFile() 
stations_path <- 
  here("data", "raw") %>%
  dir_ls(regexp = "station_info")

station <- 
  readxl::read_excel(
    stations_path, 
    .name_repair = janitor::make_clean_names
  ) %>%
  filter(str_detect(geo_loc_name, "(?i)florida keys") & !str_detect(line_id, "PL")) %>%
  select(station_id, station_class, "lon" = mean_lon, "lat" = mean_lat, line_id)

if (file_exists(transect_file)) {
  message("Reading transects shapefile")
  linestring <- st_read(transect_file)
} else {
  
  message("Creating transects.")
  lyr_name <- grep("vel_mag", names(multi_rast), value = TRUE)[1]

  polyline <-
    ((mapview::mapView(multi_rast, layer = lyr_name) +
      mapview::mapview(coast)) +
      mapview::mapview(station, xcol = "lon", ycol = "lat")
    ) %>%
    mapedit::editMap()

  linestring <- polyline$finished

  names(linestring) <- c("id", "type", "geometry")

  message(paste0("Saving transects as `", basename(transect_file), "`."))

  # save shapefile
  st_write(
    linestring,
    transect_file
  )
}
```

If needed, transects (`linestring` object) can be edited

```{r edit-transects}
if (FALSE) {
  linestring <-
    mapview::mapview(linestring) %>%
    mapedit::editMap("linestring")

  st_write(
    linestring,
    transect_file
  )
}

```


## Extract Pixels along Transects

```{r extract-along-transect}
n_layers <- nlyr(multi_rast) / length(dat_grid)

rast_names <- 
  names(dat_grid) %>% 
  rep(each = n_layers) %>% 
  as_date()

time(multi_rast)  <- rast_names
names(multi_rast) <- paste(names(multi_rast), rast_names, sep = "_")


vel_ext_transect <-
  terra::extract(multi_rast, linestring, xy = TRUE) %>%
  select(ID, x, y, contains("vel_mag")) %>%
  pivot_longer(
    cols      = c(-ID, -x, -y), # columns to pivot long,
    names_to  = "name", # desired name for category column
    values_to = "vel_mag", # desired name for value column
  ) %>%
  mutate(
    date = str_extract(name, "\\d.*"),
    date2 = as_date(date)
  ) %T>%
  print()
```


Set sufficed to file names with starting date to end date

```{r set-file-suffix}
date_suffix <- 
  c(first(rast_names), last(rast_names)) %>%
  paste0("_", skip_dates, collapse = "_") %T>% 
  print()
```


# ---- Extract Distance from Shore ----

```{r distance-from-shore}
# extract starting point of each transect
polyline_first_pt <- 
  linestring %>% 
  st_coordinates() %>%
  as_tibble(.name_repair = janitor::make_clean_names) %>%
  slice_head(by = l1) %T>% 
  print()

# join the first point of each transect to the cells extracted along the transects
dist_from_shore <-
  left_join(
    # first point from each transect
    polyline_first_pt,
    
    # extracted cells
    vel_ext_transect,
    by = c("l1" = "ID"),
    suffix = c("_shr", "_fc")
  ) %>%
  rowwise() %>%
  mutate(
    # calcualte distance from starting point to each cell along the transect
    dist = geodist_vec(
      x_shr, y_shr,
      x_fc, y_fc,
      measure = "geodesic",
      paired  = TRUE
    ) / 1000
  ) %>%
  ungroup() %T>%
  print()

dist_from_shore %>%
  # extract first value along transect >0.5 m/s
  filter(vel_mag >= 0.5) %>%
  filter(.by = c(date2, l1), dist == min(dist))

```


```{r add-line_names}
# extract transect names from stations file
# add MQ = Marquesas Key
# add second MR 
transect_names <-   
  c("MQ", arrange(station, lon)  %>%
   distinct(line_id) %>%
   pull(1)
   ) %>%
  tibble(line_name = .) %>%
  add_row(.after = 9, tibble(line_name = "MR2")) %>%
  mutate(
    rows      = row_number(),
    line_name = fct_inorder(line_name)
    )

# merge transect names
dist_from_shore2 <- 
  left_join(
    x  = dist_from_shore,
    y  = transect_names,
    by = c("l1" = "rows")
  ) %>%
  relocate(line_name, .after = l1) %T>% 
  print()

# subset values >0.5 and extract minimum distance
dist_fc <- 
  dist_from_shore2 %>%
  # extract first value along transect >0.5 m/s
  filter(vel_mag >= 0.5) %>%
  filter(.by = c(date2, line_name), dist == min(dist))
```


```{r save-extracted-data}
if (!file_exists(here("data", "processed", glue("fc_dist_{date_suffix}.csv")))) {
  dir_create(here("data", "processed"))

  dist_from_shore2 %>%
    select(
      line_name,
      "shore_lon_dd"      = x_shr,
      "shore_lat_dd"      = y_shr,
      "fl_current_lon_dd" = x_fc,
      "fl_current_lat_dd" = y_fc,
      "velocity"          = vel_mag,
      "date"              = date2,
      "distance_km"       = dist
    ) %>%
    arrange(date) %>%
    write_csv(
      here("data", "processed", glue("dist_above_5_{date_suffix}.csv")),
      na = ""
    )
}

if (!file_exists(here("data", "processed", glue("fc_dist_{date_suffix}.csv")))) {
  dist_fc %>%
    select(
      line_name,
      "shore_lon_dd"      = x_shr,
      "shore_lat_dd"      = y_shr,
      "fl_current_lon_dd" = x_fc,
      "fl_current_lat_dd" = y_fc,
      "velocity"          = vel_mag,
      "date"              = date2,
      "distance_km"       = dist
    ) %>%
    arrange(date) %>%
    write_csv(
      here("data", "processed", glue("fc_dist_{date_suffix}.csv")),
      na = ""
    )
}
```


# ---- Plots ----

TODO: try this method to show distance from shore
<https://stackoverflow.com/questions/71473958/how-to-keep-points-in-gganimate-after-each-frame-is-rendered>

```{r plot-per-transect}
dist_avg_month <- 
  dist_from_shore2 %>%
  mutate(
    months = format(date2, "%B %Y"),
    months = my(months),
         ) %>%
  summarise(
    .by = c(months, l1, line_name, dist),
    vel_mag = mean(vel_mag, na.rm = TRUE)
  ) 

dist_from_shore2 %>%
  mutate(
    months = format(date2, "%B %Y"),
    months = my(months)
    ) %>% 
  ggplot(aes(x = dist, y = vel_mag, color = date)) +
  geom_hline(yintercept = 0.5, color = "red") +
  geom_path(show.legend = FALSE) +
  geom_point(show.legend = FALSE) +
  geom_path(data = dist_avg_month,  color = "black", show.legend = FALSE) +
  geom_point(data = dist_avg_month, color = "black",  show.legend = FALSE) +
  labs(
    x = "Distance from Shore (km)", 
    y = expression("Velocity"~(m~s^-1)),
    color = "ID"
    ) +
  coord_cartesian(expand = FALSE) +
  theme_bw() +
  facet_grid(months ~ line_name)
```


```{r trasect-view}
if (FALSE) {
  
trasect_plt <- 
  dist_from_shore2 %>%
  filter(between(date2, first(date2), first(date2) + days(1))) %>%
  ggplot(aes(x = dist, y = vel_mag, color = as.factor(line_name))) +
  geom_hline(yintercept = 0.5, color = "red") +
  geom_path() +
  geom_point(size = 1) +
  labs(
    x = "Distance from Shore (km)", 
    y = expression("Velocity"~(m~s^-1)),
    color = "ID"
    ) +
  coord_cartesian(expand = FALSE) +
  theme_bw() +
  facet_wrap(~line_name) +
  theme(
    text            = element_text(size = 2),
    legend.key.size = unit(0.25, "cm"),
    legend.key.spacing = unit(0.05, "cm"),
    legend.position = "bottom",
    legend.margin   = margin(t = -10),
    axis.text       = element_blank(),
    axis.ticks      = element_blank()
    ) +
  guides(colour = "none") +
  gganimate::transition_time(date2) +
  labs(title = "Date: {frame_time}")

if (FALSE) {
  anim_save(
    file      = glue("trasect_plot4_{date_suffix}.mp4"),
    animation = trasect_plt,
    path      = animate_save,
    renderer  = ffmpeg_renderer(format = "mp4", ffmpeg = ffmpeg_path),
    
    height  = 800,
    width   = 800,
    res     = 300
    # nframes = nlyr(multi_rast),
    # fps     = 20
  )
}
}
```

For `vel_vect`, may want to have more vectors along keys so instead of filtering
for every `slice_by`, should include a polygon to keep?



```{r vars-plt-mag-vel-vectors}
slice_by      <- 5
length_divide <- 2
filt <- 
  . %>% 
  filter()
  # filter(date == first(date))

aviso_tile <- aviso_grid_tibble %>% filt
pts_lt     <- filter(vel_ext_transect, vel_mag < 0.5) %>% filt
pts_gt     <- filter(vel_ext_transect, vel_mag >= 0.5) %>% filt
vel_vect   <- slice(aviso_grid_tibble, seq(1, n(), by = slice_by)) %>% 
  filt
```


```{r mag-vel-vectors}
plt_mag_vel_vect <-
  ggplot() +
  
  # velocity pixels
  geom_tile(data = aviso_tile, aes(x = lon, y = lat, fill = vel_mag)) +

  # coast
  geom_sf(data = coast) +
  
  # velocity vectors
  geom_segment(
    data = vel_vect,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = lat, 
      yend  = lat + vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +

  # transects
  geom_sf(data = linestring, color = "red")  +

  # less than 0.5 m/s
  geom_point(data = pts_lt,
             aes(x = x,  y = y),
             color = "blue",
             size  = 0.5) +

  # greater than 0.5 m/s
  geom_point(data = pts_gt,
             aes(x = x,  y = y),
             color = "green",
             size  = 0.5) +
  
  # styling
  labs(x = NULL, y = NULL,
       color = expression("Velocity"~(m~s^-1)),
       fill = expression("Velocity"~(m~s^-1))) +
  coord_sf(expand = FALSE, ylim = ylim, xlim = xlim) +
  scale_fill_viridis_b() +
  scale_color_viridis_b(option = "magma", breaks = c(0.25, seq(0, 2, by = 0.5))) +
  # facet_wrap(~date)
  theme_bw() +
  theme(
    legend.key.size = unit(0.25, "cm"),
    text = element_text(size = 4),
    legend.position = "bottom",
    legend.margin = margin(t = -10),
    axis.text = element_blank(),
    axis.ticks = element_blank()
    ) +
  
  gganimate::transition_states(date, transition_length = 0) +
  labs(title = "Date: {closest_state}")

# save animation
anim_save(
  file      = glue("mag_vel_vect2_{date_suffix}.mp4"), 
  animation = plt_mag_vel_vect, 
  path      = animate_save, 
  renderer  = ffmpeg_renderer(format = "mp4", ffmpeg = ffmpeg_path), 
  height = 800, 
  width  = 800,
  res    = 300,
  
  # duration = 1,
  nframes  = nlyr(multi_rast),
  # fps      = 20
  )

```





# WIP: Crop along the FL Keys and add more vectors




# ---- Create Polygon ----

```{r edit-transects}
transect_file <- here(shp_save, "fl_keys_polygon.shp")

# stations_path <- rstudioapi::selectFile() 
stations_path <- 
  here("data", "raw") %>%
  dir_ls(regexp = "fknms")
station_sht   <- readxl::excel_sheets(stations_path) 
station       <- 
  readxl::read_excel(
    stations_path, 
    station_sht[9], 
    .name_repair = janitor::make_clean_names
  ) %>%
  filter(str_detect(geo_loc_name, "(?i)florida keys") & !str_detect(line_id, "PL")) %>%
  select(station_id, station_class, "lon" = mean_lon, "lat" = mean_lat, line_id)

if (file_exists(transect_file)) {
  message("Reading transects shapefile")
  linestring <- st_read(transect_file)
} else {
  
  message("Creating transects.")
  lyr_name <- grep("vel_mag", names(multi_rast), value = TRUE)[1]
  
  fl_polygon <-
    ((mapview::mapView(multi_rast, layer = lyr_name) +
      mapview::mapview(coast)) +
      mapview::mapview(station, xcol = "lon", ycol = "lat")
    ) %>%
    mapedit::editMap()

  fl_keys_poly <- fl_polygon$finished

  names(fl_keys_poly) <- c("id", "type", "geometry")

  message(paste0("Saving transects as `", basename(transect_file), "`."))
  
  st_write(
    fl_keys_poly,
    transect_file
  )
}
```

```{r}
plot(fl_keys_poly)
test2 <-
  aviso_grid_tibble %>%
  filter(date == first(date)) %>%
  st_as_sf(coords = c("lon", "lat"), remove = FALSE) %>%
  st_set_crs(st_crs(4326)) %>%
  st_crop(fl_keys_poly) %>%
  as_tibble()

test <-
  multi_rast %>%
  terra::subset(1:4) %>%
  mask(fl_keys_poly) %>%
  tidyterra::as_tibble(xy = TRUE) %>%
  rename("lon" = x, "lat" = y, "adt" = 3, "vgos" = 4, "ugos" = 5, "vel_mag" = 6)

test2 <-
  multi_rast %>%
  terra::subset(1:4) %>%
  mask(fl_keys_poly, inverse = TRUE) %>%
  tidyterra::as_tibble(xy = TRUE) %>%
  rename("lon" = x, "lat" = y, "adt" = 3, "vgos" = 4, "ugos" = 5, "vel_mag" = 6) %>%
  slice(seq(1, n(), by = slice_by))

 ggplot() +
  
  # velocity pixels
  # geom_sf(data = test2)
  geom_tile(data = test2, aes(x = lon, y = lat, fill = vel_mag),
            na.rm = TRUE) +
  geom_tile(data = test, aes(x = lon, y = lat, fill = vel_mag),
            na.rm = TRUE) +

  # coast
  geom_sf(data = coast) +
  geom_sf(data = fl_keys_poly, fill = NA) +
  # velocity vectors
  geom_segment(
    data = test,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = lat, 
      yend  = lat + vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +
  geom_segment(
    data = test2,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = lat, 
      yend  = lat + vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +

  # transects
  geom_sf(data = linestring, color = "red")  +

  # less than 0.5 m/s
  geom_point(data = filter(pts_lt, date == first(date)),
             aes(x = x,  y = y),
             color = "blue",
             size  = 0.5) +

  # greater than 0.5 m/s
  geom_point(data = filter(pts_gt, date == first(date)),
             aes(x = x,  y = y),
             color = "green",
             size  = 0.5) +
     # styling
  labs(x = NULL, y = NULL,
       color = expression("Velocity"~(m~s^-1)),
       fill = expression("Velocity"~(m~s^-1))) +
  coord_sf(expand = FALSE, ylim = ylim, xlim = xlim) +
  scale_fill_viridis_b(na.value = NA) +
  scale_color_viridis_b(option = "magma", breaks = c(0.25, seq(0, 2, by = 0.5))) +
  theme_bw()
  
  
```





# Create Transects along Shelf

```{r edit-transects}
transect_file <- here(shp_save, "transects_along.shp")

# stations_path <- rstudioapi::selectFile() 
stations_path <- 
  here("data", "raw") %>%
  dir_ls(regexp = "fknms")
station_sht   <- readxl::excel_sheets(stations_path) 
station       <- 
  readxl::read_excel(
    stations_path, 
    station_sht[9], 
    .name_repair = janitor::make_clean_names
  ) %>%
  filter(str_detect(geo_loc_name, "(?i)florida keys") & !str_detect(line_id, "PL")) %>%
  select(station_id, station_class, "lon" = mean_lon, "lat" = mean_lat, line_id)

if (file_exists(transect_file)) {
  message("Reading transects shapefile")
  linestring <- st_read(transect_file)
} else {
  
  message("Creating transects.")
  lyr_name <- grep("vel_mag", names(multi_rast), value = TRUE)[1]
  
  polyline <-
    ((mapview::mapView(multi_rast, layer = lyr_name) +
      mapview::mapview(coast)) +
      mapview::mapview(station, xcol = "lon", ycol = "lat")
    ) %>%
    mapedit::editMap()

  linestring <- polyline$finished

  names(linestring) <- c("id", "type", "geometry")

  message(paste0("Saving transects as `", basename(transect_file), "`."))
  
  st_write(
    linestring,
    transect_file
  )
}

# if need to edit the `linestring` object
if (FALSE) {
  linestring <-
    mapview::mapview(linestring) %>%
    mapedit::editMap("linestring")
  
  # select specific lines
  mapedit::selectFeatures(linestring)
  #   st_write(
  #   linestring,
  #   transect_file
  # )
}

```


```{r extract-along-transect}
n_layers <- nlyr(multi_rast) / length(dat_grid)

rast_names <- 
  names(dat_grid) %>% 
  rep(each = n_layers) %>% 
  as_date()

time(multi_rast)  <- rast_names
names(multi_rast) <- paste(names(multi_rast), rast_names, sep = "_")


vel_ext_transect <- 
 terra::extract(multi_rast, linestring, xy = TRUE) %>%
 select(ID, "lon" = x , "lat" = y, contains(c("vel_mag", "gos"))) %>%
  pivot_longer(
    cols      = c(-ID, -lon, -lat),     # columns to pivot long,
    names_to  = "name",  # desired name for category column
    values_to = "vel_mag", # desired name for value column
    ) %>%
  mutate(
    date = str_extract(name, "\\d.*"),
    date2 = as_date(date),
    name = str_remove(name, "_\\d{4}.*")
  ) %>%
  pivot_wider(
    data         = .,
    # id_cols      = c(), # *optional* vector of unaffected columns,
    names_from   = c(name), # category column(s) to pivot wide
    values_from  = c(vel_mag), # value column(s) that hold data for each category column
    names_sep    = "_",
    names_repair = janitor::make_clean_names
    ) %T>% 
  print()
```


```{r}
vel_ext_transect %>%
  filter(date2 == sample(date2, 1)) %>%
  
  ggplot() +
  # coast
  geom_sf(data = coast) +
  # geom_line(aes(x = lon, y = lat)) +
   # transects
  geom_sf(data = linestring, color = "red")  +
  
  
  # velocity vectors
  geom_segment(
    # data = vel_vect,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = lat, 
      yend  = lat + vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +
  labs(x = NULL, y = NULL) +
  scale_color_viridis_b(option = "magma", breaks = c(0.25, seq(0, 2, by = 0.5))) +
  coord_sf(ylim = c(24,26), xlim = c(-82, -80)) +
  theme_bw()
```


```{r}
vel_ext_transect %>%
  filter(between(date2, first(date2), first(date2) + 5)) %>%
  ggplot() +
 
  # velocity vectors
  geom_segment(
    # data = vel_vect,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = 0, 
      yend  = vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +
  coord_cartesian(expand = FALSE) +
  facet_wrap(~date2) +
  scale_color_viridis_b(option = "magma", breaks = c(0.25, seq(0, 2, by = 0.5))) +

  # coord_sf(ylim = c(24,26), xlim = c(-82, -80)) +
  theme_bw()

date_filt <- 
  vel_ext_transect %>%
  filter(ugos < 0 ) %>%
  distinct(date2)


vel_ext_transect %>%
  filter(date2 %in% date_filt$date2) %>%
  filter(date2 %in% sample(date_filt$date2, 6)) %>%
  arrange(date2) %>%
  # filter(between(date2, first(date2), first(date2) + 5)) %>%
  ggplot() +
 
  # velocity vectors
  geom_segment(
    # data = vel_vect,
    aes(
      x     = lon, 
      xend  = lon + ugos/length_divide, 
      y     = 0, 
      yend  = vgos/length_divide, 
      color = vel_mag
      ),
    arrow     = arrow(length = unit(0.15/2, "cm")), # adjust arrow size
    linewidth = 0.25,                              # adjust arrow thickness
    na.rm     = TRUE
  ) +
  labs(x = NULL, y = expression("Velocity"~(m~s^-1)), color = "Magnitude") +
  coord_cartesian(expand = FALSE) +
  facet_wrap(~date2) +
  scale_color_viridis_b(option = "magma", breaks = c(0.25, seq(0, 2, by = 0.5))) +

  # coord_sf(ylim = c(24,26), xlim = c(-82, -80)) +
  theme_bw()

```

